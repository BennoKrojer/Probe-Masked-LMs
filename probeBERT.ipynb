{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "probeBERT.ipynb",
      "provenance": [],
      "mount_file_id": "1x-SJSL-ayVz6lezuATBaPPilUeedtv2_",
      "authorship_tag": "ABX9TyMq7/GvosXa7rdkDtnxNoXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BennoKrojer/Probe-Masked-LMs/blob/master/probeBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcOSzM4ddYwH",
        "colab_type": "text"
      },
      "source": [
        "This is a simple Notebook to probe BERT for facts in the form \"Subject relation [clozed object]\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnH7YtxQM7Km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryq6wcjZeelZ",
        "colab_type": "text"
      },
      "source": [
        "Let's first set up our probes and some detailed settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQwkcDpP6fsJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subjects = ['France', 'Paris', 'Berlin','Haidhausen', 'Mount Everest', 'My heart']\n",
        "relation = 'is located in'\n",
        "answers = ['Europe', 'France', 'Germany', ['Munich', 'Bavaria', 'Germany'], ['Nepal', 'China'], ''] # If there is no correct answer, simply put '' in the list\n",
        "probes = [f'{subj} {relation}' for subj in subjects]\n",
        "cased_model = True\n",
        "numb_predictions_displayed = 5\n",
        "ignore_self_reference_output = True # BERT tends to predict the subject again in many cases. This can be ignored."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ru4XQlreoLg",
        "colab_type": "text"
      },
      "source": [
        "Let's probe!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRNTd42zopnR",
        "colab_type": "code",
        "outputId": "49c64abb-9e3a-4dd8-cb6d-d39a51e4ec8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM, RobertaForMaskedLM, RobertaTokenizer\n",
        "import numpy as np\n",
        "\n",
        "# from: https://huggingface.co/transformers/quickstart.html#bert-example\n",
        "\n",
        "bert_model = 'bert-large-cased' if cased_model else 'bert-large-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model)\n",
        "model = BertForMaskedLM.from_pretrained(bert_model)\n",
        "model.eval()\n",
        "\n",
        "output = {'correct': [], 'false': [], 'undefined': []}\n",
        "for probe, answer in zip(probes, answers):\n",
        "  text = f'[CLS] {probe} [MASK] . [SEP]'\n",
        "  tokenized_text = tokenizer.tokenize(text)\n",
        "  masked_index = [i for i, x in enumerate(tokenized_text) if x == '[MASK]'][0]\n",
        "  print(f'TOKENIZED TEXT: {tokenized_text}')\n",
        "\n",
        "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "  segments_ids = [0]*len(tokenized_text)\n",
        "\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "  # Predict all tokens\n",
        "  with torch.no_grad():\n",
        "      outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
        "      predictions = outputs[0][0][masked_index]\n",
        "  predicted_ids = torch.argsort(predictions, descending=True)[:numb_predictions_displayed]\n",
        "  predicted_tokens = tokenizer.convert_ids_to_tokens(list(predicted_ids))\n",
        "  if answer:\n",
        "    if isinstance(answer, str):\n",
        "      answer = [answer]\n",
        "    first_pred = predicted_tokens[0]\n",
        "    if first_pred == tokenized_text[1]:\n",
        "      first_pred = predicted_tokens[1]\n",
        "    if first_pred in answer:\n",
        "      output['correct'].append((probe, predicted_tokens))\n",
        "    else:\n",
        "      output['false'].append((probe, predicted_tokens))\n",
        "  else:\n",
        "    output['undefined'].append((probe, predicted_tokens))\n",
        "\n",
        "for key, val in output.items():\n",
        "  print(key)\n",
        "  for probe, predicted_tokens in val:\n",
        "    print(f'{probe} [MASK] → {predicted_tokens}')\n",
        "  print('\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOKENIZED TEXT: ['[CLS]', 'France', 'is', 'located', 'in', '[MASK]', '.', '[SEP]']\n",
            "TOKENIZED TEXT: ['[CLS]', 'Paris', 'is', 'located', 'in', '[MASK]', '.', '[SEP]']\n",
            "TOKENIZED TEXT: ['[CLS]', 'Berlin', 'is', 'located', 'in', '[MASK]', '.', '[SEP]']\n",
            "TOKENIZED TEXT: ['[CLS]', 'Hai', '##dha', '##use', '##n', 'is', 'located', 'in', '[MASK]', '.', '[SEP]']\n",
            "TOKENIZED TEXT: ['[CLS]', 'Mount', 'Everest', 'is', 'located', 'in', '[MASK]', '.', '[SEP]']\n",
            "TOKENIZED TEXT: ['[CLS]', 'My', 'heart', 'is', 'located', 'in', '[MASK]', '.', '[SEP]']\n",
            "correct\n",
            "France is located in [MASK] → ['France', 'Europe', 'Belgium', 'Algeria', 'Oceania']\n",
            "Paris is located in [MASK] → ['France', 'Paris', 'Normandy', 'Europe', 'Belgium']\n",
            "Berlin is located in [MASK] → ['Germany', 'Berlin', 'Poland', 'Europe', 'Switzerland']\n",
            "Haidhausen is located in [MASK] → ['Germany', 'Austria', 'Switzerland', 'Bavaria', 'Hesse']\n",
            "Mount Everest is located in [MASK] → ['Nepal', 'Afghanistan', 'Tibet', 'Pakistan', 'India']\n",
            "\n",
            "\n",
            "false\n",
            "\n",
            "\n",
            "undefined\n",
            "My heart is located in [MASK] → ['heaven', 'Paris', 'you', 'Texas', 'it']\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOB0g5qggsrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}